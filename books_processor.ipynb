{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:\n",
    "directory with book txt files\n",
    "csv with book metadata\n",
    "\n",
    "Output:\n",
    "sql script to upload Book table\n",
    "\n",
    "Book\n",
    "- title\n",
    "- author\n",
    "- publicationDate\n",
    "- genre\n",
    "- subjects[]\n",
    "- keywords[]\n",
    "- similarManuscripts[]\n",
    "- description\n",
    "- isbn13\n",
    "- isbn10\n",
    "- amazonProductUrl\n",
    "- plotStructure[]\n",
    "\n",
    "insert into \"Book\" (\"title\", \"author\", \"publicationDate\", \"genre\", \"subjects\", \"keywords\", \"similarManuscripts\", \"description\", \"cover\", \"isbn13\", \"isbn10\", \"amazonProductUrl\", \"plotStructure\", \"createdAt\", \"updatedAt\") \n",
    "\n",
    "Flow:\n",
    "read csv\n",
    "for each book generate analytics\n",
    "write output sql line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /Users/idanhahn/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/idanhahn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     /Users/idanhahn/nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/idanhahn/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/idanhahn/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/idanhahn/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/idanhahn/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/idanhahn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download([\"names\",\n",
    "\"stopwords\",\n",
    "\"state_union\",\n",
    "\"twitter_samples\",\n",
    "\"movie_reviews\",\n",
    "\"averaged_perceptron_tagger\",\n",
    "\"vader_lexicon\",\n",
    "\"punkt\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_avarage(x, w):\n",
    "  return np.convolve(x, np.ones(w)/w, mode='valid')/w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_plot_structure(book_file):\n",
    "    \"\"\"\n",
    "    Processes the books file and returns plot structure chart points.\n",
    "    \"\"\"\n",
    "    fb = open(book_file, \"r\", encoding=\"utf8\")\n",
    "    raw = fb.read()\n",
    "    lines = tokenizer.tokenize(raw)\n",
    "    x = []\n",
    "    y = []\n",
    "    for idx, line in enumerate(lines):\n",
    "        x.append(idx)\n",
    "        y.append(sia.polarity_scores(line)['compound']*100)\n",
    "    y_ma = moving_avarage(y, 1000)\n",
    "    y_norm = 100*(y_ma - min(y_ma))/(max(y_ma) - min(y_ma)) - 50\n",
    "    y_reduce = y_norm[::math.ceil(len(y_norm)/100)]\n",
    "    y_floored = [math.floor(e) for e in y_reduce]\n",
    "    if (len(y_floored) == 99):\n",
    "        y_floored.append(math.ceil(y_norm[-1]))\n",
    "    \n",
    "    return y_floored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open('./books.csv', 'r')\n",
    "output_file = open('./book_seed.sql', 'w')\n",
    "\n",
    "csvreader = csv.reader(input_file)\n",
    "header = next(csvreader)\n",
    "for row in csvreader:\n",
    "    subjects = \"{subjects}\"\n",
    "    keywords = \"{keywords}\"\n",
    "    similar_manuscripts = \"{similarManuscripts}\"\n",
    "    plot_structure_array = process_plot_structure(f'./data/{row[1]} - {row[2]}.txt')\n",
    "    plot_structure = \"{\" + f'{\",\".join([str(i) for i in plot_structure_array])}' + \"}\"\n",
    "    cover = \"cover\"\n",
    "    title = row[1].replace('\\'', '\\'\\'')\n",
    "    description = row[5].replace('\"', '').replace('\\'', '\\'\\'')\n",
    "    output_file.write(f'INSERT INTO \"Book\" \\\n",
    "      (\"title\", \"author\", \"genre\", \"publicationDate\", \"description\",  \"subjects\", \"keywords\",  \"isbn13\", \"isbn10\", \"amazonProductUrl\", \"createdAt\", \"updatedAt\") VALUES\\\n",
    "      (\\'{title}\\', \\'{row[2]}\\', \\'{row[4]}\\', \\'{row[3]}\\', \\'{description}\\', \\'{subjects}\\', \\'{keywords}\\', \\'{row[8]}\\', \\'{row[9]}\\', \\'{row[10]}\\', NOW(), NOW());\\n')\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
